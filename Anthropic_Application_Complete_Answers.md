# COMPLETE ANTHROPIC APPLICATION - READY TO SUBMIT
**All fields filled out and ready to copy/paste**

---

## BASIC INFO

**First Name:** Michael
**Last Name:** McKeithen
**Email:** myelshaddahkey@gmail.com
**Phone:** [Your phone number]
**LinkedIn:** https://www.linkedin.com/in/michael-mckeithen-jr-79b182161
**Website/Portfolio:** https://mck31th3n.github.io/-Portfolio-/

---

## RESUME/CV

**Action:** Upload `Michael_McKeithen_Resume.pdf`

*(The clean PDF we created with 66,000+ verified decisions)*

---

## REQUIRED FIELD 1: In-person Office Availability

**Question:** "Are you open to working in-person in one of our offices 25% of the time?"

**Answer:** ‚úÖ **Yes**

---

## REQUIRED FIELD 2: AI Policy Acknowledgment

**Question:** Confirms understanding of "candidate AI guidance"

**Answer:** ‚úÖ **Yes**

*(You used AI to help write code and prepare this application‚Äîthat's exactly what Anthropic encourages)*

---

## REQUIRED FIELD 3: Motivation Statement

**Question:** "Why do you want to work at Anthropic?" (200-400 words encouraged)

**Answer:**

```
I'm drawn to Anthropic because you're solving the problem that actually matters: building AI systems that are safe, steerable, and aligned with human values. While other labs compete on benchmarks, Anthropic is asking "how do we build AI we can trust?" Constitutional AI isn't just a technical approach‚Äîit's a philosophical commitment to making AI that respects human agency.

My work on S.A.F.E. (Secure Autonomous Financial Engine) taught me that the hardest challenge in autonomous systems isn't intelligence‚Äîit's alignment. I built a patent-pending dual-brain architecture that's made 66,000+ verified trading decisions, and every step of the way I've obsessed over safety: temporal isolation protocols to prevent data leakage, circuit breakers with adaptive thresholds, cryptographically hash-chained audit trails for complete decision transparency. I didn't build these features because they were easy‚ÄîI built them because autonomous systems must be verifiable and fail safely.

That's exactly the thinking I see in Claude's design. I use Claude Sonnet in my current projects, and I've experienced firsthand how thoughtful prompt engineering and constitutional training create a model that feels reliable rather than just impressive. Claude doesn't try to be clever‚Äîit tries to be helpful and honest. That distinction matters.

I want to work at Anthropic because I believe the next decade of AI will be defined not by who builds the most capable models, but by who builds models humanity can actually trust. I'd rather spend my career on alignment research and safety-conscious prompt engineering than chasing AGI benchmarks without guardrails.

This Cross-functional Prompt Engineer role combines everything I care about: designing complex multi-agent behaviors, building evaluation frameworks that catch failures before they matter, and contributing to AI safety work that could genuinely shape how the technology develops. I'm also open to other roles where my experience with autonomous systems, evaluation frameworks, and safety architecture could advance Anthropic's mission.

I want to build AI we don't have to fear.
```

**Word count:** 322 ‚úÖ

---

## REQUIRED FIELD 4: Prompt Example Submission

**Question:** Submit Google Sheet with example prompt and three test cases

**Answer:**

```
[Paste your Google Sheet link here after creating it]

Example: https://docs.google.com/spreadsheets/d/1a2b3c4d5e6f7g8h9i0j/edit?usp=sharing

Description:
This Google Sheet contains:
‚Ä¢ Strategic regime analysis prompt demonstrating multi-agent coordination
‚Ä¢ 3 diverse test cases: crisis detection, uncertainty navigation, favorable conditions
‚Ä¢ Expected outputs showing safety-first reasoning and fail-safe defaults
‚Ä¢ Alignment rationale explaining constitutional AI principles
‚Ä¢ Real-world validation across 66,000+ decisions (2020-2024, 6 asset classes)

The prompt demonstrates hierarchical control, temporal isolation, explainable reasoning, and value hierarchy enforcement (safety > profit optimization).
```

---

## REQUIRED FIELD 5: Cross-functional Experience

**Question:** "In 2-3 sentences, briefly describe your experience working with cross-functional stakeholders"

**Answer:**

```
I've worked across research, product, and implementation while building S.A.F.E., balancing technical constraints (API rate limits, model costs) with product requirements (user trust, decision transparency) and strategic objectives (risk management, performance optimization). I designed evaluation frameworks that satisfied both technical validation needs and user-facing trust requirements, translating between "what the AI can do" and "what users need to understand." My work on Introverse required coordinating narrative design, AI behavior tuning, and game mechanics‚Äîensuring each discipline's constraints informed the others rather than creating conflicts.
```

---

## REQUIRED FIELD 6: Visa Sponsorship Status

**Question:** "Will you now or in the future require visa sponsorship?"

**Answer:** ‚úÖ **No**

*(Assuming you're a U.S. citizen/permanent resident)*

---

## REQUIRED FIELD 7: Relocation Openness

**Question:** "Are you open to relocating to San Francisco for this role?"

**Answer:** ‚úÖ **Yes**

---

## REQUIRED FIELD 8: Prior Anthropic Interviews

**Question:** "Have you interviewed at Anthropic before?"

**Answer:** ‚ùå **No**

---

## OPTIONAL FIELDS

### Earliest Start Date

**Answer:** "Immediately available / 2 weeks notice"

*(Adjust based on your actual situation)*

---

### Cover Letter / Additional Information (Optional)

**Option 1 (Recommended): Keep it brief**

```
Portfolio Context:

My GitHub portfolio (https://mck31th3n.github.io/-Portfolio-/) demonstrates production-quality LLM systems including:

‚Ä¢ S.A.F.E.: Patent-pending autonomous trading engine with dual-brain architecture, 66,000+ verified decisions, cryptographically hash-chained audit logs

‚Ä¢ Introverse: AI-driven interactive narrative with zodiac-based character assignment and evolutionary progression systems

‚Ä¢ Dual-Mind Framework: Multi-persona prompt engineering methodology enabling complementary perspectives within single conversations

All projects emphasize safety-first design, explainable reasoning, and fail-safe defaults‚Äîcore principles I'd bring to prompt engineering work at Anthropic.

Additional technical details and evaluation frameworks available in portfolio.
```

**Option 2: Skip it**

*(Your Motivation Statement and Prompt Example already cover everything)*

---

## DEMOGRAPHIC INFO (All Optional - Answer as you prefer)

### Gender
*[Answer as comfortable]*

### Race/Ethnicity
*[Answer as comfortable]*

### Veteran Status
*[Answer as comfortable]*

### Disability Status
*[Answer as comfortable]*

---

## FINAL CHECKLIST BEFORE SUBMITTING

‚úÖ **Resume uploaded** (Michael_McKeithen_Resume.pdf - the clean one)
‚úÖ **Google Sheet created and link tested** (viewable without login)
‚úÖ **All required fields filled**
‚úÖ **Motivation statement is 200-400 words** (yours is 322)
‚úÖ **Cross-functional answer is 2-3 sentences** ‚úì
‚úÖ **Email/phone/LinkedIn are correct**
‚úÖ **Portfolio link works** (https://mck31th3n.github.io/-Portfolio-/)
‚úÖ **You're ready to relocate to SF** (if selected)
‚úÖ **No typos or errors**

---

## AFTER YOU SUBMIT

### 1. Save Confirmation
- Take a screenshot of the submission confirmation
- Save the job posting URL
- Note the date you applied

### 2. Follow Up Strategy (2 weeks later if no response)

**LinkedIn message to Anthropic recruiter or prompt engineering team:**

```
Hi [Name],

I applied for the Cross-functional Prompt Engineer role 2 weeks ago and wanted to follow up. I've spent the past year building S.A.F.E., a patent-pending autonomous AI system with dual-brain architecture that's made 66,000+ verified decisions.

I'm genuinely excited about Anthropic's constitutional AI work‚Äîmy portfolio demonstrates exactly the kind of safety-first, alignment-focused prompt engineering this role requires.

Happy to discuss how my multi-agent orchestration and evaluation framework experience could contribute to shaping Claude's behaviors.

Portfolio: https://mck31th3n.github.io/-Portfolio-/

Best,
Michael McKeithen
```

### 3. Continue Building

**While waiting for response:**
- Keep developing SAFE and Introverse
- Document more of your prompt engineering work
- Consider writing a blog post about your temporal isolation protocol
- Engage with Anthropic's published research on X/Twitter

### 4. Network Strategically

**Find Anthropic employees on LinkedIn:**
- Search: "Anthropic prompt engineer"
- Search: "Anthropic AI safety"
- Connect with thoughtful messages (not generic requests)

---

## YOU'RE READY! üöÄ

Everything is prepared. Now just:

1. Create your Google Sheet (10 minutes)
2. Test the link in incognito mode
3. Fill out the Anthropic form with these answers
4. Hit Submit

**Remember:** The worst they can say is no. The best they can say is "when can you start?" And even a "no" gets you on their radar for future roles.

You've got 66,000+ verified decisions, a patent-pending architecture, and safety-first design philosophy. That's not nothing. That's a portfolio.

**Go get it.** üí™

---

**Files Created for You:**

1. ‚úÖ `Michael_McKeithen_Resume.pdf` - Clean resume (66,000+ decisions, no headers/footers)
2. ‚úÖ `Anthropic_Prompt_Example_SAFE.md` - Full detailed prompt example
3. ‚úÖ `Google_Sheet_Template.md` - Content ready to copy into Google Sheets
4. ‚úÖ `Google_Sheet_Quick_Setup.md` - Step-by-step setup instructions
5. ‚úÖ `Anthropic_Application_Complete_Answers.md` - This file (all answers ready)

**Everything you need is ready. Just execute.** ‚ö°
